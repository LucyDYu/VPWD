{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# automatically reload edited modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "skip_domains = [\"siteindices.com\", \"cutestat.com\", \"clearwebstats.com\"]  # List of domains to skip\n",
    "csv.field_size_limit(10 * 1024 * 1024)  # Set the field size limit to 10 MB\n",
    "\n",
    "def data_to_text_label(data):\n",
    "    texts = [\" \".join([doc[\"domain\"], doc[\"title\"], doc[\"keyword\"], doc[\"url\"], doc[\"text\"]]) for doc in data]\n",
    "    labels = [doc[\"target\"] for doc in data]\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "def process_data(csv_reader):\n",
    "    data = []\n",
    "    seen_domains = set()\n",
    "\n",
    "    for row in csv_reader:\n",
    "        # ,domain,title,keyword,url,crawledDate,aliveDate,isPMS,html,text\n",
    "        index = row[0]\n",
    "        raw_text = row[9]\n",
    "        if raw_text == \"\":\n",
    "            continue\n",
    "        \n",
    "        domain = row[1]\n",
    "        if any(skip_domain in domain for skip_domain in skip_domains):\n",
    "            continue\n",
    "        \n",
    "        isPMS = row[7]\n",
    "        if isPMS == \"\":\n",
    "            continue\n",
    "        target = int(isPMS)\n",
    "        \n",
    "        text = re.sub(r\" {2,}\", \" \", raw_text)\n",
    "        text = re.sub(r\"^ {0,}[\\w/-]+(?: {1,}[\\w/-]+)?(?: {1,}[\\w/-]+)?(?: {1,}[\\w/-]+)?:(.*)\\n\", \"\", text,\n",
    "                      flags=re.MULTILINE)\n",
    "\n",
    "        title = row[2]\n",
    "        keyword = row[3]\n",
    "        url = row[4]\n",
    "        crawledDate = row[5]\n",
    "        aliveDate = row[6]\n",
    "\n",
    "        html = row[8]\n",
    "\n",
    "        if domain not in seen_domains:\n",
    "            data.append({\n",
    "                \"index\": index,  \n",
    "                \"domain\": domain,\n",
    "                \"title\": title,\n",
    "                \"keyword\": keyword,\n",
    "                \"url\": url,\n",
    "                \"crawledDate\": crawledDate,\n",
    "                \"aliveDate\": aliveDate,\n",
    "                \"isPMS\": isPMS,\n",
    "                \"html\": html,\n",
    "                \"text\": text,\n",
    "                \"target\": target\n",
    "            })\n",
    "            seen_domains.add(domain)\n",
    "        \n",
    "    return data\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T08:36:42.616704Z",
     "start_time": "2024-09-19T08:36:42.128095Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Labeled data (manual labeled)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 0: 313\n",
      "Count of 1: 254\n",
      "Total manual labeled data: 567\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "\n",
    "CORPUS_PATH = \"data/manual_labeled.csv\"\n",
    "\n",
    "with open(CORPUS_PATH, \"r\", encoding=\"utf-8\") as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)  # Skip the first line\n",
    "    data_manual = process_data(csv_reader)\n",
    "            \n",
    "    \n",
    "texts, labels = data_to_text_label(data_manual)\n",
    "\n",
    "data_dict[\"CH\"] = {\"texts\": texts, \"labels\": labels}\n",
    "\n",
    "count_0 = labels.count(0)\n",
    "count_1 = labels.count(1)\n",
    "print(\"Count of 0:\", count_0)\n",
    "print(\"Count of 1:\", count_1)\n",
    "print(\"Total manual labeled data:\", count_0 + count_1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T08:36:43.938305Z",
     "start_time": "2024-09-19T08:36:43.756581Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Labeled data (manual and model-assisted labeled)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 0: 2965\n",
      "Count of 1: 2794\n",
      "Total labeled data: 5759\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "\n",
    "CORPUS_PATH = \"data/manual_and_self_train.csv\"\n",
    "\n",
    "with open(CORPUS_PATH, \"r\", encoding=\"utf-8\") as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)  # Skip the first line\n",
    "    data = process_data(csv_reader)\n",
    "            \n",
    "    \n",
    "texts, labels = data_to_text_label(data)\n",
    "\n",
    "data_dict[\"CH\"] = {\"texts\": texts, \"labels\": labels}\n",
    "\n",
    "count_0 = labels.count(0)\n",
    "count_1 = labels.count(1)\n",
    "print(\"Count of 0:\", count_0)\n",
    "print(\"Count of 1:\", count_1)\n",
    "print(\"Total labeled data:\", count_0 + count_1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T08:36:47.877659Z",
     "start_time": "2024-09-19T08:36:45.437841Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# All data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 14254\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "\n",
    "CORPUS_PATH = \"data/all_data.csv\"\n",
    "\n",
    "data_all = []\n",
    "seen_domains = set()\n",
    "\n",
    "with open(CORPUS_PATH, \"r\", encoding=\"utf-8\") as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)  # Skip the first line\n",
    "    for row in csv_reader:\n",
    "        # ,domain,title,keyword,url,crawledDate,aliveDate,isPMS,html,text\n",
    "        if \",domain,title\" in row:\n",
    "            continue\n",
    "        if len(row) < 10:\n",
    "            continue\n",
    "        index = row[0]\n",
    "        raw_text = row[9]\n",
    "        if raw_text == \"\":\n",
    "            continue\n",
    "\n",
    "        domain = row[1]\n",
    "        if any(skip_domain in domain for skip_domain in skip_domains):\n",
    "            continue\n",
    "\n",
    "            \n",
    "        isPMS = row[7]\n",
    "        # if isPMS == \"\":\n",
    "        #     continue\n",
    "        target = isPMS\n",
    "        \n",
    "        text = re.sub(r\" {2,}\", \" \", raw_text)\n",
    "        text = re.sub(r\"^ {0,}[\\w/-]+(?: {1,}[\\w/-]+)?(?: {1,}[\\w/-]+)?(?: {1,}[\\w/-]+)?:(.*)\\n\", \"\", text,\n",
    "                      flags=re.MULTILINE)\n",
    "            \n",
    "        title = row[2]\n",
    "        keyword = row[3]\n",
    "        url = row[4]\n",
    "        crawledDate = row[5]\n",
    "        aliveDate = row[6]\n",
    "\n",
    "        html = row[8]\n",
    "\n",
    "            \n",
    "        if domain not in seen_domains:\n",
    "            data_all.append({\n",
    "                \"index\": index,  \n",
    "                \"domain\": domain,\n",
    "                \"title\": title,\n",
    "                \"keyword\": keyword,\n",
    "                \"url\": url,\n",
    "                \"crawledDate\": crawledDate,\n",
    "                \"aliveDate\": aliveDate,\n",
    "                \"isPMS\": isPMS,\n",
    "                \"html\": html,\n",
    "                \"text\": text,\n",
    "                \"target\": target\n",
    "            })\n",
    "            seen_domains.add(domain)\n",
    "            \n",
    "\n",
    "print(\"Total data:\", len(data_all))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T08:36:52.411451Z",
     "start_time": "2024-09-19T08:36:47.881157Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Disclaimer**: The data is collected from the internet and may contain inappropriate content. The data is used for research purposes only. The data is not suitable for commercial use. Please use the data at your own discretion."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
